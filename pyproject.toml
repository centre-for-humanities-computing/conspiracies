[project]
name = "conspiracies"
version = "0.7.0"
authors = [
    {name = '"Kenneth Enevoldsen'},
    {name = "Lasse Hansen"},
    {name = "Ekaterina Borisova"},
    {name = 'Stephan Smuts"'},
]
description = "Discover and examine conspiracies using natural language processing"
classifiers = [
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Operating System :: POSIX :: Linux",
    "Operating System :: MacOS :: MacOS X",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.7",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "License :: OSI Approved :: MIT License",
]
requires-python = ">=3.8"
dependencies = [
    "spacy>=3.3.2,<3.6.0",
    "spacy-transformers>=1.1.2,<1.2.0",
    "confection>0.0.1,<0.1.0",
    # allenNLP packages
    "allennlp>=2.10.0,<2.11.0",
    "allennlp-models>=2.10.0,<2.11.0",
    # transformers
    "transformers>=4.11.3,<4.19.0",
    # base+ 
    "torch>=1.6.0,<1.12.0",
    "numpy>=1.19.5,<1.24.0",
    "pandas>=1.1.5,<1.5.0",
    "jsonlines>=3.1.0,<3.2.0",
    "openai",
    "ndjson",
    "networkx",
    "matplotlib",
    "umap-learn",
    "hdbscan",
    "sentence-transformers",
    "stop-words",
    "bs4",
    "toml"
]

[project.license]
file = "LICENSE"
name = "MIT"

[project.urls]
homepage = "https://github.com/centre-for-humanities-computing/conspiracies"
repository = "https://github.com/centre-for-humanities-computing/conspiracies"
documentation = "https://centre-for-humanities-computing.github.io/conspiracies/"

[project.optional-dependencies]
style = [
    "black==22.12.0",
    "pre-commit>=2.20.0,<2.21.0",
    "ruff==0.0.191",
    "mypy==0.991"
]
tests = [
    "pytest>=7.1.3,<7.3.0",
    "pytest-cov>=3.0.0,<3.1.0",
]
docs = [
    "sphinx>=5.3.0,<5.4.0",
    "furo==2022.12.7",
    "sphinx-copybutton>=0.5.1,<0.5.2",
    "sphinxext-opengraph>=0.7.3,<0.7.4",
    "sphinx_design>=0.3.0,<0.3.1",
    "myst-nb>=0.6.0,<1.17.0",
    "sphinx_togglebutton>=0.2.3,<0.4.0",
]
tutorials = [
    "jupyter>=1.0.0,<1.1.0"
]
openai = [
    "openai>=0.26.5,<0.27.0"
]

[project.readme]
file = "README.md"
content-type = "text/markdown"


[project.entry-points.spacy_factories]
"prompt_relation_extraction" = "conspiracies.docprocessing.relationextraction.gptprompting:create_prompt_relation_extraction_component"
"relation_extractor" = "conspiracies.docprocessing.relationextraction.multi2oie:make_relation_extractor"
"allennlp_coref" = "conspiracies.docprocessing.coref:create_coref_component"
"heads_extraction" = "conspiracies.docprocessing.headwordextraction:create_headwords_component"


[build-system]
requires = ["setuptools>=61.0.0", "wheel", "setuptools_scm"]
build-backend = "setuptools.build_meta"


[tool.coverage.run]
omit = [
    "**/tests/*",
    "**/_vendorized/*",
    "**/about.py",
]

exclude_lines = [
    "pragma: no cover",
    # Don't complain about missing debug-only code:
    "def __unicode__",
    "def __repr__",
    "if self.debug",
    # Don't complain if tests don't hit defensive assertion code:
    "raise AssertionError",
    "raise NotImplementedError",
    # Don't complain if non-runnable code isn't run:
    "if 0:",
    "if __name__ == .__main__.:",
]

[tool.setuptools]
include-package-data = true
zip-safe = false

[tool.distutils.bdist_wheel]
universal = true

[tool.distutils.sdist]
formats = "gztar"


[tool.mypy]
ignore_missing_imports = true
no_implicit_optional = true

[tool.semantic_release]
branch = "main"
version_variable = [
    "pyproject.toml:version"
]
build_command = "python -m pip install build; python -m build"

[tool.ruff]
exclude = [
    ".venv",
    ".env",
    ".git",
    "__pycache__",
    "paper"
]